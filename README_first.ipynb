{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "41c3e3bb",
   "metadata": {},
   "source": [
    "# Training HuggingFace ðŸ¤— Models on an IPU using Paperspace Gradient\n",
    "\n",
    "Whether you are looking to generate images with Stable Diffusion, derive insights from text, or need to recognize audio samples, the examples in here have you covered. And by using Paperspace to access IPUs you can be up and running in minutes!\n",
    "\n",
    "## Getting Started with our interactive notebooks\n",
    "\n",
    "You will learn how to use IPUs in a Jupyter-style notebook. Amongst other applications, you will be able to use IPUs to train models including vision transformers (ViT) for images, BERT-Large for question answering, and text classification.\n",
    "\n",
    "## Graphcore Hugging Face models\n",
    "\n",
    "To familurise yourself with IPU related programming start here with our Introduction to ðŸ¤— Optimum Graphcore: BERT Fine-tuning on IPUs notebook you can find it within: \n",
    "\n",
    "```\n",
    "    natural-language-processing\n",
    "    â””â”€â”€â”€introduction_to_optimum_graphcore.ipynb\n",
    "```\n",
    "\n",
    "For dedicated finetuning, inference, advanced ML and IPU related notebooks checkout the following notebooks:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd57fcd8",
   "metadata": {},
   "source": [
    "<details><summary><big> Fine-tune our models on your datasets</summary><br/>\n",
    "Here are our notebooks on how to use datasets to fine-tune HuggingFace checkpoints.\n",
    "\n",
    "Interested in <b>audio processing</b>? Check out how to fine-tune a pre-trained wav2vec 2.0 model with PyTorch on the IPU. Which can be found within: \n",
    "\n",
    "    audio-processing\n",
    "        â””â”€â”€â”€wav2vec2-fine-tuning-checkpoint.ipynb\n",
    "\n",
    "This <b>image classification</b> notebook will show you how to preprocess the data and fine-tune a pretrained model on image classification. Check it out here:\n",
    "\n",
    "    image-classification\n",
    "        â””â”€â”€â”€image-classification.ipynb\n",
    "\n",
    "#### Natural Language Processing\n",
    "\n",
    "Check out our NLP notebooks to help you get you started on fine-tuning your models for a range of different tasks. Show how to preprocess the data and fine-tune a pretrained model on a range of datasets including WMT, SWAG, SQUAD and many more in our NLP notebooks:\n",
    "\n",
    "```\n",
    "    natural-language-processing/\n",
    "        â””â”€â”€â”€translation.ipynb\n",
    "        â””â”€â”€â”€other-use-cases/\n",
    "            â””â”€â”€â”€ multiple_choice.ipynb\n",
    "            â””â”€â”€â”€ question_answering.ipynb\n",
    "            â””â”€â”€â”€ text_classification.ipynb\n",
    "            â””â”€â”€â”€ token_classification.ipynb\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee810189",
   "metadata": {},
   "source": [
    "<details><summary><big> Use ðŸ¤— model checkpoints for inference</summary>\n",
    "\n",
    "Here you can learn how to use Hugging Face checkpoints directly for inference. \n",
    "\n",
    "#### Natural Language Processing\n",
    "    \n",
    "Our NLP notebooks show how to run inference with only 2 lines of code! \n",
    "    \n",
    "Use the sentiment-analysis pipeline to quickly evaluate pre-trained models and check out how to use Gradio and pipelines to prototype a web application doing fast token classification in our name entity extraction notebooks here:\n",
    "\n",
    "```\n",
    "    natural-language-processing\n",
    "        â””â”€â”€â”€sentiment_analysis.ipynb\n",
    "        â””â”€â”€â”€name-entity-extraction.ipynb\n",
    "```\n",
    "\n",
    "    \n",
    "#### Inference for Audio Processing\n",
    "    \n",
    "To run inference on <b>audio segments</b> checkout our wav2vec2 notebook for inference on how to run inference using PyTorch:\n",
    "\n",
    "```\n",
    "    audio-processing\n",
    "        â””â”€â”€â”€wav2vec2-inference-checkpoint.ipynb\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42f0b63",
   "metadata": {},
   "source": [
    "<details><summary><big> Build your own models</summary>\n",
    "    \n",
    "Interested in porting your own models onto the Hugging Face platform? Then you're in the right place.\n",
    "    \n",
    "Show how to train a model for causal or masked language modelling from scratch, and learn how to train an external that is not supported by Optimum or Transformers here:\n",
    "\n",
    "```\n",
    "    natural-language-processing\n",
    "        â””â”€â”€â”€other-use-cases/\n",
    "                â””â”€â”€â”€language_modelling_from_scratch.ipynb\n",
    "                â””â”€â”€â”€external_model.ipynb\n",
    "    \n",
    "```\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2cc02c",
   "metadata": {},
   "source": [
    "<details><summary><big> Stable Diffusion</summary>\n",
    "\n",
    "Explore our more advanced examples with our range of Stable Diffusion notebooks!\n",
    "    \n",
    "Here you can run Stable Diffusion 2 (Conditional UNet) on text-to-image tasks, or run a Stable Diffusion (Conditional UNet) pipeline for text-to-image, image-to-image and inpainting tasks:\n",
    "\n",
    "```\n",
    "    stable-diffusion/\n",
    "        â””â”€â”€â”€text_to_image_sd2.ipynb\n",
    "        â””â”€â”€â”€text_to_image.ipynb\n",
    "        â””â”€â”€â”€image_to_image.ipynb\n",
    "        â””â”€â”€â”€inpainting.ipynb\n",
    "```\n",
    "    \n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8b8d7a",
   "metadata": {},
   "source": [
    "\n",
    "### Useful tips\n",
    "Finally, the [Managing IPU resources](useful-tips/managing_ipu_resources.ipynb) notebook contains information about how to make best use of the IPU resources. For example monitoring IPU use, releasing IPUs when you are not using them, and then re-attaching your model to the IPU when you start again.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "9409b80169a82c0207afe9a460d7f88a38094a708839df55a31910312ecdb1ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
