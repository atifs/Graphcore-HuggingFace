{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02f76e55-3d57-41bb-97e4-46531fc68e3d",
   "metadata": {},
   "source": [
    "# Training Hugging Face Models on an IPU using Paperspace Gradient\n",
    "\n",
    "The notebooks in this runtime are designed to help you solve the problems you face by leveraging the power of deep learning and the speed of the Graphcore IPU.\n",
    "Whether you are looking to generate images with Stable Diffusion, derive insights from text, or need to recognize audio samples, the examples in here have you covered. And by using Paperspace to access IPUs you can be up and running in minutes!\n",
    "\n",
    "These examples will show you how to use and train Hugging Face models which run on Graphcore IPUs using the Paperspace Gradient environment.\n",
    "\n",
    "You will learn how to use IPUs in a Jupyter-style notebook. Amongst other applications, you will be able to use IPUs to train models including vision transformers (ViT) for images, BERT-Large for question answering, and text classification.\n",
    "\n",
    "## Graphcore Hugging Face models\n",
    "\n",
    "Hugging Face provides convenient access to pre-trained transformer models. The integration between Hugging Face and Graphcore makes it easy to fine-tune and run these models on an IPU in Gradient.\n",
    "\n",
    "To help you get started, we have some real-world examples including Stable Diffusion, speech recognition, natural language processing and image manipulation. These are based on [ðŸ¤— Optimum Graphcore](https://github.com/huggingface/optimum-graphcore), the interface between [ðŸ¤— Transformers](https://github.com/huggingface/transformers) and [Graphcore IPUs](https://www.graphcore.ai/products/ipu).\n",
    "\n",
    "These worked examples will help you get started running your application on the IPU. They also demonstrate techniques such as data-parallelism and pipelining to increase performance by using multiple IPUs.\n",
    "\n",
    "## Getting started\n",
    "\n",
    "While no specific user setup is required to train IPU models on Gradient, many of the notebooks in this runtime will download from and push model checkpoints to the Hugging Face model Hub. For the best experience we recommend that you generate a [User Access Token](https://huggingface.co/docs/hub/security-tokens) with \"Write\" access to your Hugging Face account. By doing so, the checkpoints from the models you fine tune will automatically be saved and be available for you to use later. Without this token, some models may fail to train and you may need to set the `push_to_hub` argument to false in the `IPUTrainingArguments` class before starting IPU training.\n",
    "\n",
    "## Natural language processing\n",
    "\n",
    "The best places to start in the [natural-language-processing](natural-language-processing) folder are:\n",
    "\n",
    "* The [sentiment analysis notebook](natural-language-processing/sentiment_analysis.ipynb) which shows how a pre-trained model can very easily be run on the IPU, allowing fast inference. It walks through the use of increasingly sophisticated models to classify text showing the wide range of possibilities that is made available by the integration of Graphcore's IPU into the Hugging Face ecosystem.\n",
    "\n",
    "* [Introduction to ðŸ¤— Optimum Graphcore: BERT Fine-tuning on IPUs](natural-language-processing/introduction_to_optimum_graphcore.ipynb) uses a BERT model to introduce the process of running on the IPU. This could be a good starting point to get familiar with the IPU, even if this isnâ€™t your main area of interest. It has a good introduction to pipelining an application across multiple IPUs.\n",
    "\n",
    "Beyond these two notebooks, several others are available showing inference and fine-tuning, for tasks such as answering questions, summarising text, and translation.\n",
    "\n",
    "## Stable Diffusion\n",
    "\n",
    "The [Stable Diffusion](stable-diffusion) folder contains several ready to run examples of generative tasks using Stable Diffusion v1.5 and v2.0. Tasks such as text-to-image, image-to-image and inpainting are all available.\n",
    "\n",
    "## Speech recognition\n",
    "\n",
    "The [audio-processing](audio-processing) folder contains notebooks for automatic speech recognition.\n",
    "\n",
    "There are two notebooks that use a wav2vec 2.0 model. The first for [fine-tuning the model](audio-processing/wav2vec2-fine-tuning-checkpoint.ipynb) and then for [running inference](audio-processing/wav2vec2-inference-checkpoint.ipynb) on the output of that. For more information, see the fine-tuning notebook.\n",
    "\n",
    "## Useful tips\n",
    "\n",
    "Finally, the [useful-tips](useful-tips) folder contains information about how to make best use of the IPU resources. For example monitoring IPU use, releasing IPUs when you are not using them, and then re-attaching your model to the IPU when you start again.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6.9 ('3.0.0+1145_poptorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "vscode": {
   "interpreter": {
    "hash": "9409b80169a82c0207afe9a460d7f88a38094a708839df55a31910312ecdb1ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
